# 用来配置 merge-seqfile 所需要的配置信息
# 此文件存放在HDFS上
###########################################################################
######################### CDH集群访问的 相关配置 #########################
# CDH 集群使用的安全策略，kerberos 或 simple
hadoop_security_authentication=kerberos
#hadoop_security_authentication=simple
# CDH 集群如果使用kerberos安全策略的话，kerberos的配置文件的位置
#krb5_conf=/etc/krb5.conf
#krb5_conf=C:\\Program Files\\MIT\\Kerberos\\krb5-WY.ini
krb5_conf=G:\\Users\\lkz\\IdeaProjects\\data_analysis\\conf\\krb5.conf
# 访问 CDH Hive 的用户、keytab文件位置
hive_user=mrdas@WY.CMDI.CMCC
#hive_user=hive@WY.CMDI.CMCC
#hive_keytab=C:\\Program Files\\MIT\\Kerberos\\mrdas-WY.keytab
hive_keytab=G:\\Users\\lkz\\IdeaProjects\\data_analysis\\conf\\mrdas.keytab
mromerge_conf_hdfs=/test/test_lkz_other/prop/lkz-test-mromerge-conf-v5.properties

comp_merge=/mro/comp_seqfiles_test
######################### Hive表相关配置 #########################
#  beeline 连接的用户字符串
beeline_user=jdbc:hive2://could004:10000/
beeline_principal=hive/could004@WY.CMDI.CMCC
# Hive中用来存放合并后的MRO数据的 数据库名
dbname=test_lkz
# Hive中用来存放合并后的MRO数据的 表名、表文件存放路径
tb_name=test_lkz_mro_dt_rec_v5
tb_location=/test/test_lkz/test_lkz_mro_dt_rec_v4
# Hive中用来存放合并后的MRO数据的 表 的压缩算法，默认为 "snappy"
tb_compress=snappy

######################### 数据合并程序 产生的log的 相关配置 #########################
# merge-data.sh产生日志的目录
#log_dir=/home/aspire/zhangyan/datacollection/logs/
log_dir=D:\\Workspace\\bigdata\\code\\trunk\\datacollection\\merge-seqfile\\logs
# Spark merge-seqfile的日志级别，可选值 ERROR、INFO、DEBUG、TRACE
log_level=INFO
# 日志数据库访问方式
# could008
pgdb_ip=10.254.222.226
pgdb_port=5432
pgdb_user=zhangyan
pgdb_passwd=#Mrdas17P19!
pgdb_db=mlogdb

