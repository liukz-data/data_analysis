# 用来配置 merge-seqfile 所需要的配置信息
# 此文件存放在HDFS上
###########################################################################
######################### CDH集群访问的 相关配置 #########################
# CDH 集群使用的安全策略，kerberos 或 simple
hadoop_security_authentication=kerberos
#hadoop_security_authentication=simple
# CDH 集群如果使用kerberos安全策略的话，kerberos的配置文件的位置
krb5_conf=/etc/krb5.conf
# 访问 CDH Hive 的用户、keytab文件位置
hive_user=mrdas@WY.CMDI.CMCC
hive_keytab=/home/mrdas/mrdas.keytab

comp_merge=/mro/comp_merge
######################### Hive表相关配置 #########################
#  beeline 连接的用户字符串
beeline_user=jdbc:hive2://could004:10000/
beeline_principal=hive/could004@WY.CMDI.CMCC


######################### 数据合并程序 产生的log的 相关配置 #########################
# merge-data.sh产生日志的目录
#log_dir=/home/aspire/zhangyan/datacollection/logs/
# Spark merge-seqfile的日志级别，可选值 ERROR、INFO、DEBUG、TRACE
log_level=DEBUG
# 日志数据库访问方式
# could008
pgdb_ip=10.254.222.226
pgdb_port=5432
pgdb_user=zhangyan
pgdb_passwd=#Mrdas17P19!
pgdb_db=mlogdb

